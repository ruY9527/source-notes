## 								个人工作履历



####  在校期间

​	TODO



#### 技术栈

  Java基础熟练(有看过一些Java源码),

  Spring(有看源码)/SpringBoot/SpringCloud使用熟练

  MyBatis,Jpa,Mongo,Redis,Kafka 使用熟练

  了解点前端和python.

   大数据中组件也有点了解(计划学习中)	

------



####  ICIL (2019-07 ~ 至今) ,  国际物流/仓储 ,  深圳

####    Label-Service + Airflow

​	 	这里使用airflow(pyton)的原因,方便快速与第三方进行对接和内部一些定时任务(主要是生成execl和报表数据).   label-service是单独的一个微服务,也是内存的,目的在于是提供内部的common接口,需要与第三方打印label等接口,都在这个服务中实现。这样就避免了,内部其他服务如果需要与第三方对接的话,就需要在写一套的问题。

​         **这里的亮点个人觉得,使用axon框架来记录与第三方进行对接的情况,根据event来查询每次的情况一目了然,这样与第三方进行汇总(费用计算)的时候,是非常清晰的.对于后期需要生成的报表也是非常的好的. **  Airflow这里的作用就是,通过python脚本的特性,快速,接入第三方的数据,很快。比如我们从第三方平台(shopify)等这种,接过来orders信息,然后丢给内部存库系统,就可以很快速的实现.

​        总结 :  对Apollo配置中心,Eureka,Feign,Kafka,Airflow等使用熟练,并且项目中遇见的问题,加强了对框架内部执行原理的理解。



####   同步服务

​	  这个服务就有三个微服务组成的一个大的基础服务. Sync / Number / Milestone.

​      我这边主要是负责 Sync服务. Sync1.0主要是与canal1.1直接相互,来读取数据库来进行数据同步(这里肯定是二边的表是完全不一样的,不然就话,就会直接使用canal开发的来通过,或者通过mysql主从来同步,正是因为不能,所以就有了这个服务).  Sync2.0,我负责的, canal1.0升级到1.3,同时sync不直接与canal交互,加入kafka来加交互.  也就是Canal --> Kafka --> Sync(公司项目)  ---(Feign) --> (Number/Milestone). 

​    **这里的亮点就是Kafka会拉取大量的数据, 然后根据公司内部的逻辑进行封装相应的逻辑(主要即使处理如果一条数据再这批Kafka的数据中,既有Insert/Update/Delete三个Action的话,那么就需要进行分类处理).之前是都是单个处理处理,所以性能是很低的,并且遇见了问题(通信问题,rds连接失败等问题的话,程序就基本阻塞了,这是肯定不行的). 然后这版如果是遇见了这种异常的话,就会保存文件,然后定时去执行.**

​       还有一个亮点,下游的Number Service因为部署了二个,所以优化为采用异步处理,也就是来了数据就就到kafka中,并且kafka是集群模式(3台),所以也就是有三个borker,故有三个线程消费数据,又因为是有二个实例,也就是二台server是可能拿到重复的数据,所以在保存数据的逻辑地方需要进行加分布式锁处理(这里我们采用redission来实现).

------



####  FPI(实习2018-11  ~  2019-05) , 环保业务 , 武汉

​		在FPI最初的时候,想起来好像做到的最多的东西就是分析数据。虽然后面对基础服务的拆分,我这边也就拆了二个服务模块出来,然后负责新开发一个。

​		

##### 	 大气网格基础服务(All in one)

​	 技术点 :  SpringBoot1.x + JDBC Template  MongoDB  Kafka Flyway  (这里关于操作DB的都封装成一个类,注入到Spring容器中,只需要注入这个封装的类,来调用方法即可)

​	dev : gitlab + gitlab(CI/CD) + gitlab runner .(项目管理也是使用gitlab)		

​	功能(我负责) : 最初的一版就是直接基于这个项目来些的,前端需要提供的所有的接口都是基于项目来提供(前后端分离,还是移动端)。 我就负责开发几个报告的接口.  **根据输入的天到MongoDB里面查询每个站点的每天的信息(六因子)** 。 **根据站点名称(这里的站点是有层级关系的.),天范围,来查询六因子,AQI等信息,并且同时进行同比/环比等分析。**   **根据天范围(周/月)等从MongoDB中查询出值,根据需求提供的,比如AQI > 250 就是严重污染等,行分析(这里是提供分析接口给前端UI,使用echarts来做图形)。** 后面的拆分都是基于这个服务,来将里面的功能拆分出来.



####  拆分微服务

​    对大气网格基础服务进行拆分, 根据对应的模块来拆分成不同的微服务应用. **个人认为这样的好处,就是对每个模块进行最大的复用,并且都有对应的人员负责,理解起单独的业务更快.还是一点最主要的是，我们这个系统可以给城市A使用,不需要修改什么,按照模块(这里拆出来的模块),根据需求的需要,也可以在城市B使用,这个就需要看每个城市具体的需要了.**     签到微服务(sign-service), 这里我还单独负责一个签到的微服务开发,主要是根据网格员的打卡的位置,和配置的对应获取点位信息(经纬度),类似于每天上下班打卡,最后出周/月/时间段 的报表统计API. 然后根据每个网格员的点位信息,传递给前端用来地图展示。根据一段时间的经纬度来判断网格员是否有偷懒的问题. 这里主要的难点, 每个网格员每天的点位信息怎么存储 ?  每五分中一条,难道来一条就insert 一条 ？那这样得存储多少条啊？ 这里是使用 json 字段来存储点位信息,然后预留三个字段,经纬度,时间即可.